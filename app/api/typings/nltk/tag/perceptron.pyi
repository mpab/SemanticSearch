"""
This type stub file was generated by pyright.
"""

from nltk.tag.api import TaggerI
from nltk import jsontags

PICKLE = ...
@jsontags.register_tag
class AveragedPerceptron:
    """An averaged perceptron, as implemented by Matthew Honnibal.

    See more implementation details here:
        https://explosion.ai/blog/part-of-speech-pos-tagger-in-python
    """
    json_tag = ...
    def __init__(self, weights=...) -> None:
        ...
    
    def predict(self, features, return_conf=...):
        """Dot-product the features and current weights and return the best label."""
        ...
    
    def update(self, truth, guess, features):
        """Update the feature weights."""
        ...
    
    def average_weights(self):
        """Average weights from all iterations."""
        ...
    
    def save(self, path):
        """Save the pickled model weights."""
        ...
    
    def load(self, path):
        """Load the pickled model weights."""
        ...
    
    def encode_json_obj(self):
        ...
    
    @classmethod
    def decode_json_obj(cls, obj):
        ...
    


@jsontags.register_tag
class PerceptronTagger(TaggerI):
    """
    Greedy Averaged Perceptron tagger, as implemented by Matthew Honnibal.
    See more implementation details here:
        https://explosion.ai/blog/part-of-speech-pos-tagger-in-python

    >>> from nltk.tag.perceptron import PerceptronTagger

    Train the model

    >>> tagger = PerceptronTagger(load=False)

    >>> tagger.train([[('today','NN'),('is','VBZ'),('good','JJ'),('day','NN')],
    ... [('yes','NNS'),('it','PRP'),('beautiful','JJ')]])

    >>> tagger.tag(['today','is','a','beautiful','day'])
    [('today', 'NN'), ('is', 'PRP'), ('a', 'PRP'), ('beautiful', 'JJ'), ('day', 'NN')]

    Use the pretrain model (the default constructor)

    >>> pretrain = PerceptronTagger()

    >>> pretrain.tag('The quick brown fox jumps over the lazy dog'.split())
    [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]

    >>> pretrain.tag("The red cat".split())
    [('The', 'DT'), ('red', 'JJ'), ('cat', 'NN')]
    """
    json_tag = ...
    START = ...
    END = ...
    def __init__(self, load=...) -> None:
        """
        :param load: Load the pickled model upon instantiation.
        """
        ...
    
    def tag(self, tokens, return_conf=..., use_tagdict=...):
        """
        Tag tokenized sentences.
        :params tokens: list of word
        :type tokens: list(str)
        """
        ...
    
    def train(self, sentences, save_loc=..., nr_iter=...):
        """Train a model from sentences, and save it at ``save_loc``. ``nr_iter``
        controls the number of Perceptron training iterations.

        :param sentences: A list or iterator of sentences, where each sentence
            is a list of (words, tags) tuples.
        :param save_loc: If not ``None``, saves a pickled model in this location.
        :param nr_iter: Number of training iterations.
        """
        ...
    
    def load(self, loc):
        """
        :param loc: Load a pickled model at location.
        :type loc: str
        """
        ...
    
    def encode_json_obj(self):
        ...
    
    @classmethod
    def decode_json_obj(cls, obj):
        ...
    
    def normalize(self, word):
        """
        Normalization used in pre-processing.
        - All words are lower cased
        - Groups of digits of length 4 are represented as !YEAR;
        - Other digits are represented as !DIGITS

        :rtype: str
        """
        ...
    


if __name__ == "__main__":
    ...
